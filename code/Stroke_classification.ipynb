{"cells":[{"cell_type":"markdown","source":["Colab使用說明，請先點選左上角執行階段=>變更執行階段類型=>硬體加速器選擇GPU，接著回到頁面點選右上角的連線，接著執行下方儲存格"],"metadata":{"id":"ApaN4e9gZYmz"}},{"cell_type":"markdown","source":["醫學影像專題 \n","影像資料集:\n"],"metadata":{"id":"U6ZC0wdBZhx8"}},{"cell_type":"markdown","source":["DWI_train:\n","https://drive.google.com/file/d/1QKmvbv0WtH4NVXLwFRyyzUsEXdeopX16/view?usp=sharing"],"metadata":{"id":"geKbDrwna0FN"}},{"cell_type":"markdown","source":["ADC_train:\n","https://drive.google.com/file/d/1U7rhxYlplmdk1aDeF6QIxHJx7W_lXoaR/view?usp=sharing"],"metadata":{"id":"BXJs3Oiiaiee"}},{"cell_type":"markdown","source":["ADC_val:\n","https://drive.google.com/file/d/1VFR1eytz4cDvT2z9wMwQmHM7TDv4bHr6/view?usp=sharing"],"metadata":{"id":"7a46Mtp1ainN"}},{"cell_type":"markdown","source":["ADC_test:\n","https://drive.google.com/file/d/1d-rHSj0VjYoNpfysa1Vv_ngol24oj-YY/view?usp=sharing"],"metadata":{"id":"pn0G5vwfaixf"}},{"cell_type":"markdown","source":["Label資料(test為黑箱測試，請同學將ADC_test的預測結果填入test_data.csv中)"],"metadata":{"id":"BkH0CzLIbOlU"}},{"cell_type":"markdown","source":["train:https://drive.google.com/file/d/1I682ZQsIk-_bLgmsNT4x3KAVDRrkK9z4/view?usp=sharing"],"metadata":{"id":"hEiPEQr9bUMs"}},{"cell_type":"markdown","source":["validation: https://drive.google.com/file/d/1cxYHnISzkBdJ7PtbGfpdnlrX5XG3M6Qx/view?usp=sharing"],"metadata":{"id":"cd10J_MQbUP4"}},{"cell_type":"markdown","source":["test:https://drive.google.com/file/d/1CaP57HKhwfzz5uIbdBRTcWHdQEvTUGtJ/view?usp=sharing"],"metadata":{"id":"TFWJCHS6cENh"}},{"cell_type":"markdown","source":["請將所有相關資料存入自己的google drive"],"metadata":{"id":"7u4o6LYNclua"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cb3hIQVa5np5"},"outputs":[],"source":["#@title 加載google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"EG8c5YUSWPel"},"source":["將資料移到colab的content資料夾儲存"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAHperDeOruH"},"outputs":[],"source":["import shutil\n","shutil.copyfile(\"/content/drive/My Drive/ADC_PNG_val_bias.zip\",\"/content/val.zip\")\n","shutil.unpack_archive(\"/content/val.zip\",\"/content\")\n","shutil.copyfile(\"/content/drive/My Drive/ADC_PNG_test_bias.zip\",\"/content/test.zip\")\n","shutil.unpack_archive(\"/content/test.zip\",\"/content\")\n","shutil.copyfile(\"/content/drive/My Drive/DWI_PNG_train_bias.zip\",\"/content/train.zip\")\n","shutil.unpack_archive(\"/content/train.zip\",\"/content\")\n","shutil.copyfile(\"/content/drive/My Drive/train_data.csv\",\"/content/train_data.csv\")\n","shutil.copyfile(\"/content/drive/My Drive/val_data.csv\",\"/content/val_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3NXScluW5xXx"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","source":["!pip install albumentations==0.4.6\n"],"metadata":{"id":"YSm0NSYjpkzA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5JYzJUvy535e"},"source":["# Dataset(獲取影像的部分不要更動)\n","\n","---\n","\n","\n","**非常重要**，因為資料集給的是一個病患好幾張切片，我們要取中間18張切片影像，為了確保所有人進行預測的影像切片都相同，所以請不要更改每個病患獲取的切片數量及變更影像順序"]},{"cell_type":"markdown","source":["病患人數為1977、660、660，資料集比例分為6:2:2"],"metadata":{"id":"p0rsRgOOexZK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBbZcVR85xaz"},"outputs":[],"source":["import os\n","from torch.utils.data import Dataset\n","from pathlib import Path\n","import csv\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","import pandas as pd\n","import numpy as np\n","import cv2 as cv\n","from natsort import natsorted\n","import random\n","import torch\n","\n","np.random.seed(2)\n","random.seed(2)\n","torch.manual_seed(2)\n","torch.cuda.manual_seed_all(2)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","class IMAGE_Dataset(Dataset):\n","    def __init__(self,root_dir, label_root, transfrom = None):\n","        self.root_dir = Path(root_dir)\n","        self.labels = []\n","        self.transfrom = transfrom\n","        self.label_root = Path(label_root)\n","        self.patient = []\n","        \n","        patient_path = natsorted(os.listdir(root_dir))\n","        for i in patient_path:\n","          self.patient.append(os.path.join(root_dir,i))\n","        print(len(self.patient))\n","\n","        label_df = pd.read_csv(label_root, encoding= 'unicode_escape')\n","        for j in range(len(self.patient)):\n","            label_df1 = np.array(label_df.poor_3m[label_df[\"PseudoNo\"] == int(patient_path[j])])\n","            for i in range(len(label_df1)):\n","                self.labels.append(label_df1[i])\n","        print(len(self.labels))     \n","\n","    def __len__(self):\n","        return len(self.patient)\n","\n","    def __getitem__(self, index):\n","        patients = natsorted(os.listdir(self.patient[index]))\n","        start = int((len(patients)-18)/2)\n","        img_first = cv.imread(os.path.join(self.root_dir,self.patient[index],patients[start]))\n","        img_first = cv.cvtColor(img_first,cv.COLOR_BGR2GRAY)\n","        if self.transfrom is not None:\n","            img_first = self.transfrom(image = img_first)[\"image\"]\n","        img_first = np.array(img_first)\n","        img_first = torch.from_numpy(img_first)\n","        img_first = img_first.float().div(255)\n","        img_first = img_first.unsqueeze(0)\n","        \n","        for i in range(start+1,start+18):\n","          img1 = cv.imread(os.path.join(self.root_dir,self.patient[index],patients[i]))\n","          img1 = cv.cvtColor(img1,cv.COLOR_BGR2GRAY)\n","          if self.transfrom is not None:\n","            img1 = self.transfrom(image = img1)[\"image\"]\n","          img1 = np.array(img1)\n","          img1 = torch.from_numpy(img1)\n","          img1 = img1.float().div(255)\n","          img1 = img1.unsqueeze(0)\n","          img_first = torch.cat((img_first,img1),0)\n","\n","        label = self.labels[index]\n","\n","        return img_first, label"]},{"cell_type":"markdown","metadata":{"id":"hOxUZxEZ6Y3X"},"source":["#Train\n","\n","\n","> 請注意，由於code為了方便檢視，將資料儲存在最外層(意思就是colab down之後，資料就會不見，請記得更改儲存路徑)\n","\n","\n","---\n","\n","\n","> 在這裡可以發揮您的創造力去改變模型以及任何超參數"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1WshnHL6YGZ"},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import time\n","import os\n","from torch.utils.data import Dataset\n","from pathlib import Path\n","import copy\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import torchvision.models as models\n","import albumentations as Album\n","from tqdm import tqdm\n","import numpy as np\n","import random\n","\n","Train_Root = \"/content/DWI_PNG_train_bias\"\n","Val_Root = \"/content/DWI_PNG_val_bias\"\n","Train_Label_Root = \"/content/train_data.csv\"\n","Val_Label_Root = '/content/val_data.csv'\n","\n","CUDA_DEVICES = 0\n","\n","# Initial learning rate\n","init_lr = 0.01\n","\n","# Setting learning rate operation\n","def adjust_lr(optimizer, epoch):\n","    # 1/10 learning rate every 5 epochs\n","    lr = init_lr * (0.1 ** (epoch // 5))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","def train():\n","    bestvalacc=0\n","    train_transform = Album.Compose([                                                                                  \n","        Album.Resize(224,224),\n","        Album.Normalize(mean=0,std=1)                \n","    ])\n","        \n","    train_set = IMAGE_Dataset(Path(Train_Root), Path(Train_Label_Root), train_transform)\n","    data_loader = DataLoader(dataset=train_set, batch_size=16, shuffle=True, num_workers=0)\n","    val_set = IMAGE_Dataset(Path(Val_Root), Path(Val_Label_Root), train_transform)\n","    val_data_loader = DataLoader(dataset=val_set, batch_size=16, shuffle=False, num_workers=0)\n","    classes = [\"0\",\"1\"]\n","    classes.sort()\n","    classes.sort(key = len)\n","    \n","    model=models.resnet50(pretrained=True)\n","    model.conv1=nn.Conv2d(18, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    model.fc=nn.Linear(in_features=2048, out_features=2, bias=True)\n","    #print(model)\n","\n","    print(\"==========\")\n","\n","    model = model.cuda(CUDA_DEVICES)\n","\n","    model.train()\n","\n","    best_model_params = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    \n","    best_val_model_params = copy.deepcopy(model.state_dict())\n","    best_val_acc = 0.0\n","    \n","    # Training epochs\n","    num_epochs = 30 #20改3\n","    criterion = nn.CrossEntropyLoss()\n","    \n","    # Optimizer setting\n","    optimizer = torch.optim.SGD(params=model.parameters(), lr=init_lr, momentum=0.9)\n","\n","    # Log \n","    with open('TrainingAccuracy.txt','w') as fAcc:\n","        print('Accuracy\\n', file = fAcc)\n","    with open('TrainingLoss.txt','w') as fLoss:\n","        print('Loss\\n', file = fLoss)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        localtime = time.asctime( time.localtime(time.time()) )\n","        print('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,num_epochs,localtime))\n","        print('-' * len('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,num_epochs,localtime)))\n","\n","        training_loss = 0.0\n","        training_corrects = 0\n","        adjust_lr(optimizer, epoch)\n","\n","        for i, (inputs, labels) in enumerate(tqdm(data_loader)):\n","\n","            inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","            labels = Variable(labels.cuda(CUDA_DEVICES))\n","            \n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            \n","            _, preds = torch.max(outputs.data, 1)\n","\n","            loss = criterion(outputs, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            training_loss += float(loss.item() * inputs.size(0))\n","            training_corrects += torch.sum(preds == labels.data)\n","            \n","        training_loss = training_loss / len(train_set)\n","        training_acc = training_corrects.double() /len(train_set)\n","        print('Training loss: {:.4f}\\taccuracy: {:.4f}\\n'.format(training_loss,training_acc))\n","\n","        # Check best accuracy model ( but not the best on test )\n","        if training_acc > best_acc:\n","            best_acc = training_acc\n","            best_model_params = copy.deepcopy(model.state_dict())\n","\n","\n","        with open('TrainingAccuracy.txt','a') as fAcc:\n","            print('{:.4f} '.format(training_acc), file = fAcc)\n","        with open('TrainingLoss.txt','a') as fLoss:\n","            print('{:.4f} '.format(training_loss), file = fLoss)\n","\n","        model = model.cuda(CUDA_DEVICES)\n","        model.eval()\n","        total_correct = 0\n","        total = 0\n","        class_correct = list(0. for i in enumerate(classes))\n","        class_total = list(0. for i in enumerate(classes))\n","\n","        with torch.no_grad():\n","            for inputs, labels in tqdm(val_data_loader):\n","                inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","                labels = Variable(labels.cuda(CUDA_DEVICES))\n","\n","                outputs = model(inputs)\n","                \n","                _, predicted = torch.max(outputs.data, 1)\n","                \n","                # totoal\n","                total += labels.size(0)\n","                total_correct += (predicted == labels).sum().item()\n","                c = (predicted == labels).squeeze()\n","                \n","                # batch size\n","                for i in range(labels.size(0)):\n","                    label = labels[i]\n","                    class_correct[label] += c[i].item()\n","                    class_total[label] += 1\n","\n","            for i, c in enumerate(classes):\n","                print('Accuracy of %5s : %8.4f %%' % (\n","                c, 100 * class_correct[i] / class_total[i]))\n","\n","            # Accuracy\n","            print('\\nAccuracy on the ALL test images: %.4f %%'\n","              % (100 * total_correct / total))\n","            val_acc = 100 * total_correct / total\n","        print('val accuracy: {:.4f}\\n'.format(val_acc))\n","        if val_acc >= best_val_acc:\n","            best_val_acc = val_acc\n","            best_val_model_params = copy.deepcopy(model.state_dict())\n","            torch.save(model, '/content/drive/My Drive/seq-resnet50-model-{:.2f}-best_val_acc.pth'.format(val_acc))\n","    total = sum([param.nelement() for param in model.parameters()])\n","    print(\"Number of parameter: %.2fM\" % (total/1e6))\n","    # Save best training/valid accuracy model ( not the best on test )\n","    model.load_state_dict(best_model_params)\n","    best_model_name = '/content/drive/My Drive/seq-resnet50-model-{:.2f}-best_train_acc.pth'.format(best_acc)\n","    torch.save(model, best_model_name)\n","    print(\"Best model name : \" + best_model_name)\n","if __name__ == '__main__':\n","    train()"]},{"cell_type":"markdown","metadata":{"id":"08IH9wIs6jgz"},"source":["# Test\n","\n","\n","> 可以在此增加其他常見的評估指標(F1、AUC...)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRM5ZTiu5xdv"},"outputs":[],"source":["from torch.functional import Tensor\n","import torch\n","from torch.autograd import Variable\n","from torchvision import transforms\n","from pathlib import Path\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from itertools import cycle\n","import albumentations as Album\n","from tqdm import tqdm\n","\n","\n","CUDA_DEVICES = 0\n","Test_Root = '/content/DWI_PNG_val_bias'\n","Test_Label_Root = '/content/val_data.csv'\n","PATH_TO_WEIGHTS = '/content/drive/My Drive/seq-resnet50-model-46.06-best_val_acc.pth'  # Your model name\n","\n","def test():\n","    data_transform = Album.Compose([                           \n","        Album.Resize(224,224),\n","        Album.Normalize(mean=0,std=1),                                             \n","    ])\n","    test_set = IMAGE_Dataset(Path(Test_Root), Path(Test_Label_Root), data_transform)\n","    data_loader = DataLoader(dataset=test_set, batch_size=16, shuffle=False, num_workers=0)\n","    classes = [\"0\",\"1\"]\n","    classes.sort()\n","\n","    # Load model\n","    model = torch.load(PATH_TO_WEIGHTS)\n","\n","    model.eval()\n","\n","    total_correct = 0\n","    total_false = 0\n","    total = 0\n","    class_correct = list(0. for i in enumerate(classes))\n","    class_total = list(0. for i in enumerate(classes))\n","\n","    with torch.no_grad():\n","        for inputs, labels in tqdm(data_loader):\n","            inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","            labels = Variable(labels.cuda(CUDA_DEVICES))\n","            \n","            outputs = model(inputs)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            # totoal\n","            total += labels.size(0)\n","            total_correct += (predicted == labels).sum().item()\n","            total_false += (predicted != labels).sum().item()\n","            c = (predicted == labels).squeeze()\n","            for i in range(labels.size(0)):\n","                  label = labels[i]\n","                  class_correct[label] += c[i].item()\n","                  class_total[label] += 1\n","           \n","    for i, c in enumerate(classes):\n","        print('Accuracy of %5s : %8.4f %%' % (c, 100 * class_correct[i] / class_total[i]))\n","    # Accuracy\n","    print('\\nAccuracy on the ALL test images: %.4f %%'\n","          % (100 * total_correct / total))\n","\n","if __name__ == \"__main__\":\n","    test()"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1RCDU1redI_x0HoHbUL5aZRIcokoT0JGQ","authorship_tag":"ABX9TyOPF5yFbJ1tqiC8XYtyBq2y"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}